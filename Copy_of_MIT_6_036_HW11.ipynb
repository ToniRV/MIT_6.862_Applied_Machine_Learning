{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of MIT 6.036 HW11.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ToniRV/MIT_6.862_Applied_Machine_Learning/blob/master/Copy_of_MIT_6_036_HW11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q58cS9antfCw",
        "colab_type": "text"
      },
      "source": [
        "#MIT 6.036 Spring 2020: Homework 11#\n",
        "\n",
        "This colab notebook provides code and a framework for question 6 from [homework 11](https://lms.mitx.mit.edu/courses/course-v1:MITx+6.036+2020_Spring/courseware/Week11/week11_homework/).  You can work out your solutions here, then submit your results back on the homework page when ready.\n",
        "\n",
        "## <section>**Setup**</section>\n",
        "\n",
        "First, download the code distribution for this homework that contains test cases and helper functions.\n",
        "\n",
        "Run the next code block to download and import the code for this lab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUEtSZRdtmI2",
        "colab_type": "code",
        "outputId": "a18c02a8-a15f-4f9d-c80b-6ff274debe6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "!rm -rf code_for_hw11* __MACOSX data .DS_Store\n",
        "!wget --quiet https://introml.odl.mit.edu/cat-soop/_static/6.036/homework/hw11/code_for_hw11.zip\n",
        "!unzip code_for_hw11.zip\n",
        "!mv code_for_hw11/* .\n",
        "\n",
        "import code_for_hw11 as code_for_hw11\n",
        "from rnn_hw11 import *\n",
        "from util import *\n",
        "\n",
        "import numpy as np\n",
        "import math as m\n",
        "import random\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  code_for_hw11.zip\n",
            "  inflating: code_for_hw11/rnn_hw11.py  \n",
            "  inflating: code_for_hw11/sm.py     \n",
            "  inflating: code_for_hw11/util.py   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jnw4bt5QKLJ",
        "colab_type": "text"
      },
      "source": [
        "<h1> BPTT in code:</h1>\n",
        "\n",
        "Complete the following implementation of BPTT. This is a method in an RNN class (if you're interested, the rest of the RNN class can be viewed in `rnn_hw11.py`.by clicking the files icon on the left of the colab).\n",
        "\n",
        "The instance (`self`) has attributes that define the RNN, in particular:\n",
        "\n",
        "*  The weight matrices and offsets: `self.Wss`, `self.Wsx`, `self.Wo`, `self.Wss0` and `self.Wo0`\n",
        "*  The activation functions and their derivatives: `self.f1`, `self.df1`, `self.f2`, `self.df2`\n",
        "*  The loss function and the derivative of the combined loss and final activation (as we did for feedforward networks): `self.loss_fn` and `self.dloss_f2`\n",
        "*  The dimensions of states (hidden), inputs and outputs: `self.hidden_dim`, `self.input_dim`, `self.output_dim`\n",
        "*  The initial state and, the current state: `self.init_state` and `self.hidden_state`\n",
        "*  The step size for gradient descent: `self.step_size`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfPqvLUsQXtQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bptt(self, xs, dLtdz2, states):\n",
        "    dWsx = np.zeros_like(self.Wsx)\n",
        "    dWss = np.zeros_like(self.Wss)\n",
        "    dWo = np.zeros_like(self.Wo)\n",
        "    dWss0 = np.zeros_like(self.Wss0)\n",
        "    dWo0 = np.zeros_like(self.Wo0)\n",
        "    # Derivative of future loss (from t+1 forward) wrt state at time t\n",
        "    # initially 0;  will pass \"back\" through iterations\n",
        "    dFtdst = np.zeros((self.hidden_dim, 1))\n",
        "    k = xs.shape[1]\n",
        "    # Technically we are considering time steps 1..k, but we need\n",
        "    # to index into our xs and states with indices 0..k-1\n",
        "    for t in range(k-1, -1, -1):\n",
        "        # Get relevant quantities\n",
        "        xt = xs[:, t:t+1]\n",
        "        st = states[:, t:t+1]\n",
        "        stm1 = states[:, t-1:t] if t-1 >= 0 else self.init_state\n",
        "        dLtdz2t = dLtdz2[:, t:t+1]\n",
        "        # Compute gradients step by step\n",
        "        # ==> Use self.df1(st) to get dfdz1;\n",
        "        # ==> Use self.Wo, self.Wss, etc. for weight matrices\n",
        "        # derivative of loss at time t wrt state at time t\n",
        "        dLtdst = np.transpose(self.Wo)@dLtdz2t # Your code\n",
        "        # derivatives of loss from t forward\n",
        "        dFtm1dst = dFtdst + dLtdst            # Your code\n",
        "        dFtm1dz1t = self.df1(st)*dFtm1dst # Your code\n",
        "        dFtm1dstm1 = np.transpose(self.Wss)@dFtm1dz1t # Your code\n",
        "        # gradienst wrt weights\n",
        "        dLtdWo = dLtdz2t@np.transpose(st) # Your code\n",
        "        dLtdWo0 = dLtdz2t # Your code\n",
        "        dFtm1dWss = dFtm1dz1t@np.transpose(stm1) # Your code\n",
        "        dFtm1dWss0 = dFtm1dz1t          # Your code\n",
        "        dFtm1dWsx = dFtm1dz1t@np.transpose(xt)            # Your code\n",
        "        # Accumulate updates to weights\n",
        "        dWsx += dFtm1dWsx\n",
        "        dWss += dFtm1dWss\n",
        "        dWss0 += dFtm1dWss0\n",
        "        dWo += dLtdWo\n",
        "        dWo0 += dLtdWo0\n",
        "        # pass delta \"back\" to next iteration\n",
        "        dFtdst = dFtm1dstm1\n",
        "    return dWsx, dWss, dWo, dWss0, dWo0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDiVytnhTssj",
        "colab_type": "code",
        "outputId": "ee5a906a-a063-4098-cbb0-f6a4d4ddcd7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        }
      },
      "source": [
        "\n",
        "def delay_num_test(bptt, delay = 1, num_epochs = 10000, num_seqs = 10000, seq_length = 10, step_size = .005):\n",
        "  '''\n",
        "  This is a test function provided to help you debug your implementation\n",
        "\n",
        "  In case we want to initialize.  Now just for delay = 1\n",
        "  # Wsx = np.array([[1.], [0.]])\n",
        "  # Wss = np.array([[0., 0.],\n",
        "  #              [1., 0.]])\n",
        "  # Wo = np.array([[0., 1.]])\n",
        "  # Wss0 = np.array([[0.], [0.0]])\n",
        "  # Wo0 = np.array([[0.]])\n",
        "  '''\n",
        "  np.random.seed(0)\n",
        "  data = []\n",
        "  for _ in range(num_seqs):\n",
        "    vals = np.random.random((1, seq_length))\n",
        "    x = np.hstack([vals, np.zeros([1, delay])])\n",
        "    y = np.hstack([np.zeros((1, delay)), vals])\n",
        "    data.append((x, y))\n",
        "  m = (delay + 1) * 2\n",
        "  RNN.bptt = bptt\n",
        "  rnn = RNN(1, m, 1, quadratic_loss, lambda z: z, quadratic_linear_gradient, step_size, lambda z: z, lambda z: 1)\n",
        "  # Wsx = Wsx, Wo = Wo, Wss = Wss, Wo0 = Wo0, Wss0 = Wss0)\n",
        "  rnn.train_seq_to_seq(data, num_epochs)\n",
        "  assert np.all(np.isclose(rnn.Wsx, np.array([[0.00856855],\n",
        "        [0.01936238],\n",
        "        [0.01382334],\n",
        "        [0.00771265]])))\n",
        "  assert np.all(np.isclose(rnn.Wss, np.array([[0.01505222, 0.02059889, 0.01594291, 0.00558242],\n",
        "        [0.00824307, 0.01741733, 0.01864768, 0.01079751],\n",
        "        [0.01577334, 0.0124164 , 0.0171516 , 0.0071486 ],\n",
        "        [0.00722321, 0.00497032, 0.00514737, 0.00979516]])))\n",
        "  assert np.all(np.isclose(rnn.Wo, np.array([[0.02522786, 0.01744193, 0.01995478, 0.0084726 ]])))\n",
        "  assert np.all(np.isclose(rnn.Wss0, np.array([[0.01502946],\n",
        "        [0.01181406],\n",
        "        [0.02051297],\n",
        "        [0.00716202]])))\n",
        "  assert np.all(np.isclose(rnn.Wo0, np.array([[0.42198824]])))\n",
        "  print(\"Test passed!\")\n",
        "  return (rnn.Wsx, rnn.Wss, rnn.Wo, rnn.Wss0, rnn.Wo0)\n",
        "\n",
        "delay_num_test(bptt)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training error 0.04945571303681596\n",
            "training error 0.048114092792055106\n",
            "training error 0.04850511140924504\n",
            "training error 0.04834714371014377\n",
            "training error 0.04845429552158349\n",
            "training error 0.048195163749529306\n",
            "training error 0.0490306116336328\n",
            "training error 0.048476636551466105\n",
            "training error 0.048258029080159005\n",
            "Test passed!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0.00856855],\n",
              "        [0.01936238],\n",
              "        [0.01382334],\n",
              "        [0.00771265]]),\n",
              " array([[0.01505222, 0.02059889, 0.01594291, 0.00558242],\n",
              "        [0.00824307, 0.01741733, 0.01864768, 0.01079751],\n",
              "        [0.01577334, 0.0124164 , 0.0171516 , 0.0071486 ],\n",
              "        [0.00722321, 0.00497032, 0.00514737, 0.00979516]]),\n",
              " array([[0.02522786, 0.01744193, 0.01995478, 0.0084726 ]]),\n",
              " array([[0.01502946],\n",
              "        [0.01181406],\n",
              "        [0.02051297],\n",
              "        [0.00716202]]),\n",
              " array([[0.42198824]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShWvMXLjeFK5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pi46p3vZeTVm",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    }
  ]
}