{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MIT 6.036 HW11.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ToniRV/MIT_6.862_Applied_Machine_Learning/blob/master/MIT_6_036_HW11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q58cS9antfCw",
        "colab_type": "text"
      },
      "source": [
        "#MIT 6.036 Spring 2020: Homework 11#\n",
        "\n",
        "This colab notebook provides code and a framework for question 6 from [homework 11](https://lms.mitx.mit.edu/courses/course-v1:MITx+6.036+2020_Spring/courseware/Week11/week11_homework/).  You can work out your solutions here, then submit your results back on the homework page when ready.\n",
        "\n",
        "## <section>**Setup**</section>\n",
        "\n",
        "First, download the code distribution for this homework that contains test cases and helper functions.\n",
        "\n",
        "Run the next code block to download and import the code for this lab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUEtSZRdtmI2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "e4d2edc4-62c0-4f63-f592-26d866de5369"
      },
      "source": [
        "!rm -rf code_for_hw11* __MACOSX data .DS_Store\n",
        "!wget --quiet https://introml.odl.mit.edu/cat-soop/_static/6.036/homework/hw11/code_for_hw11.zip\n",
        "!unzip code_for_hw11.zip\n",
        "!mv code_for_hw11/* .\n",
        "\n",
        "import code_for_hw11 as code_for_hw11\n",
        "from rnn_hw11 import *\n",
        "from util import *\n",
        "\n",
        "import numpy as np\n",
        "import math as m\n",
        "import random\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  code_for_hw11.zip\n",
            "  inflating: code_for_hw11/rnn_hw11.py  \n",
            "  inflating: code_for_hw11/sm.py     \n",
            "  inflating: code_for_hw11/util.py   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jnw4bt5QKLJ",
        "colab_type": "text"
      },
      "source": [
        "<h1> BPTT in code:</h1>\n",
        "\n",
        "Complete the following implementation of BPTT. This is a method in an RNN class (if you're interested, the rest of the RNN class can be viewed in `rnn_hw11.py`.by clicking the files icon on the left of the colab).\n",
        "\n",
        "The instance (`self`) has attributes that define the RNN, in particular:\n",
        "\n",
        "*  The weight matrices and offsets: `self.Wss`, `self.Wsx`, `self.Wo`, `self.Wss0` and `self.Wo0`\n",
        "*  The activation functions and their derivatives: `self.f1`, `self.df1`, `self.f2`, `self.df2`\n",
        "*  The loss function and the derivative of the combined loss and final activation (as we did for feedforward networks): `self.loss_fn` and `self.dloss_f2`\n",
        "*  The dimensions of states (hidden), inputs and outputs: `self.hidden_dim`, `self.input_dim`, `self.output_dim`\n",
        "*  The initial state and, the current state: `self.init_state` and `self.hidden_state`\n",
        "*  The step size for gradient descent: `self.step_size`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfPqvLUsQXtQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bptt(self, xs, dLtdz2, states):\n",
        "    dWsx = np.zeros_like(self.Wsx)\n",
        "    dWss = np.zeros_like(self.Wss)\n",
        "    dWo = np.zeros_like(self.Wo)\n",
        "    dWss0 = np.zeros_like(self.Wss0)\n",
        "    dWo0 = np.zeros_like(self.Wo0)\n",
        "    # Derivative of future loss (from t+1 forward) wrt state at time t\n",
        "    # initially 0;  will pass \"back\" through iterations\n",
        "    dFtdst = np.zeros((self.hidden_dim, 1))\n",
        "    k = xs.shape[1]\n",
        "    # Technically we are considering time steps 1..k, but we need\n",
        "    # to index into our xs and states with indices 0..k-1\n",
        "    for t in range(k-1, -1, -1):\n",
        "        # Get relevant quantities\n",
        "        xt = xs[:, t:t+1]\n",
        "        st = states[:, t:t+1]\n",
        "        stm1 = states[:, t-1:t] if t-1 >= 0 else self.init_state\n",
        "        dLtdz2t = dLtdz2[:, t:t+1]\n",
        "        # Compute gradients step by step\n",
        "        # ==> Use self.df1(st) to get dfdz1;\n",
        "        # ==> Use self.Wo, self.Wss, etc. for weight matrices\n",
        "        # derivative of loss at time t wrt state at time t\n",
        "        dLtdst = None        # Your code\n",
        "        # derivatives of loss from t forward\n",
        "        dFtm1dst = None            # Your code\n",
        "        dFtm1dz1t = None           # Your code\n",
        "        dFtm1dstm1 = None          # Your code\n",
        "        # gradienst wrt weights\n",
        "        dLtdWo = None              # Your code\n",
        "        dLtdWo0 = None             # Your code\n",
        "        dFtm1dWss = None           # Your code\n",
        "        dFtm1dWss0 = None          # Your code\n",
        "        dFtm1dWsx = None           # Your code\n",
        "        # Accumulate updates to weights\n",
        "        dWsx += dFtm1dWsx\n",
        "        dWss += dFtm1dWss\n",
        "        dWss0 += dFtm1dWss0\n",
        "        dWo += dLtdWo\n",
        "        dWo0 += dLtdWo0\n",
        "        # pass delta \"back\" to next iteration\n",
        "        dFtdst = dFtm1dstm1\n",
        "    return dWsx, dWss, dWo, dWss0, dWo0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDiVytnhTssj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "f185f2b8-11e9-4b85-d66d-62ee762275d3"
      },
      "source": [
        "\n",
        "def delay_num_test(bptt, delay = 1, num_epochs = 10000, num_seqs = 10000, seq_length = 10, step_size = .005):\n",
        "  '''\n",
        "  This is a test function provided to help you debug your implementation\n",
        "\n",
        "  In case we want to initialize.  Now just for delay = 1\n",
        "  # Wsx = np.array([[1.], [0.]])\n",
        "  # Wss = np.array([[0., 0.],\n",
        "  #              [1., 0.]])\n",
        "  # Wo = np.array([[0., 1.]])\n",
        "  # Wss0 = np.array([[0.], [0.0]])\n",
        "  # Wo0 = np.array([[0.]])\n",
        "  '''\n",
        "  np.random.seed(0)\n",
        "  data = []\n",
        "  for _ in range(num_seqs):\n",
        "    vals = np.random.random((1, seq_length))\n",
        "    x = np.hstack([vals, np.zeros([1, delay])])\n",
        "    y = np.hstack([np.zeros((1, delay)), vals])\n",
        "    data.append((x, y))\n",
        "  m = (delay + 1) * 2\n",
        "  RNN.bptt = bptt\n",
        "  rnn = RNN(1, m, 1, quadratic_loss, lambda z: z, quadratic_linear_gradient, step_size, lambda z: z, lambda z: 1)\n",
        "  # Wsx = Wsx, Wo = Wo, Wss = Wss, Wo0 = Wo0, Wss0 = Wss0)\n",
        "  rnn.train_seq_to_seq(data, num_epochs)\n",
        "  assert np.all(np.isclose(rnn.Wsx, np.array([[0.00856855],\n",
        "        [0.01936238],\n",
        "        [0.01382334],\n",
        "        [0.00771265]])))\n",
        "  assert np.all(np.isclose(rnn.Wss, np.array([[0.01505222, 0.02059889, 0.01594291, 0.00558242],\n",
        "        [0.00824307, 0.01741733, 0.01864768, 0.01079751],\n",
        "        [0.01577334, 0.0124164 , 0.0171516 , 0.0071486 ],\n",
        "        [0.00722321, 0.00497032, 0.00514737, 0.00979516]])))\n",
        "  assert np.all(np.isclose(rnn.Wo, np.array([[0.02522786, 0.01744193, 0.01995478, 0.0084726 ]])))\n",
        "  assert np.all(np.isclose(rnn.Wss0, np.array([[0.01502946],\n",
        "        [0.01181406],\n",
        "        [0.02051297],\n",
        "        [0.00716202]])))\n",
        "  assert np.all(np.isclose(rnn.Wo0, np.array([[0.42198824]])))\n",
        "  print(\"Test passed!\")\n",
        "  return (rnn.Wsx, rnn.Wss, rnn.Wo, rnn.Wss0, rnn.Wo0)\n",
        "\n",
        "delay_num_test(bptt)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-bd12407c7821>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWsx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWss0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWo0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mdelay_num_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbptt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-bd12407c7821>\u001b[0m in \u001b[0;36mdelay_num_test\u001b[0;34m(bptt, delay, num_epochs, num_seqs, seq_length, step_size)\u001b[0m\n\u001b[1;32m     23\u001b[0m   \u001b[0mrnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquadratic_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquadratic_linear_gradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0;31m# Wsx = Wsx, Wo = Wo, Wss = Wss, Wo0 = Wo0, Wss0 = Wss0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m   \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_seq_to_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m   assert np.all(np.isclose(rnn.Wsx, np.array([[0.00856855],\n\u001b[1;32m     27\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0;36m0.01936238\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/rnn_hw11.py\u001b[0m in \u001b[0;36mtrain_seq_to_seq\u001b[0;34m(self, training_seqs, epochs, print_interval)\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0;31m# compare_grads(grads, grads_n)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msgd_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdLdZ2s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m             \u001b[0mtotal_train_err\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mavg_seq_train_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mprint_interval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/rnn_hw11.py\u001b[0m in \u001b[0;36msgd_step\u001b[0;34m(self, xs, dLdz2s, states, gamma1, gamma2, fudge)\u001b[0m\n\u001b[1;32m    100\u001b[0m     def sgd_step(self, xs, dLdz2s, states,\n\u001b[1;32m    101\u001b[0m                  gamma1 = 0.9, gamma2 = 0.999, fudge = 1.0e-8):\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mdWsx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdWss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdWo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdWss0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdWo0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbptt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdLdz2s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWsx\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdWsx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWss\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdWss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-d3a08827186d>\u001b[0m in \u001b[0;36mbptt\u001b[0;34m(self, xs, dLtdz2, states)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mdFtm1dWsx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m           \u001b[0;31m# Your code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m# Accumulate updates to weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mdWsx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdFtm1dWsx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mdWss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdFtm1dWss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mdWss0\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdFtm1dWss0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: ufunc 'add' output (typecode 'O') could not be coerced to provided output parameter (typecode 'd') according to the casting rule ''same_kind''"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShWvMXLjeFK5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}